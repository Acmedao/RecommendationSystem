# Recommender Systems with Generative Retrieval  

链接：https://arxiv.org/abs/2305.05065

1. 要解决什么问题？ 
   1. 召回阶段传统方法需要为每个item训练学习一个emb，并构建索引，当item规模达到数十亿时，内存和计算成本高昂  
   2. 新加入的item缺乏和用户的交互，很难被召回到
   3. 多样性不够，点积相似度的召回可能会有流行度偏差的问题，说白了就是召回被头部的热门emb绑架，导致内容缺乏多样性
2. 怎么解决的
   1. 提出了一种新的框架RQ—VAE，为每个item训练学习一个语义ID，后面细说这东西是咋生成，总之这个生成语义ID的优势在于相似物品之间的语义ID会比较接近，
   解决了新内容id扩展这一块的问题，就是说任何item都可以通过RQ-VAE得到一个语义ID
   2. 之后按用户行为时间序列组装语义ID序列，来训练一个Transformer模型，自回归的预测用户下一个可能交互物品的语义ID，替换了传统的emb匹配和相似检索的过程
3. 我的问题
   1. 传统的方式将模型训练和召回剥离开来，上线很方便，这里虽然把这两个阶段合并为了一个，但线上请求时自回归的生成方式肯定是要超时的，这东西我理解只能离线召回了之后存储到redis中以KV的形式上线
   2. RQ-VAE生成出来的语义ID在Transformer中是如何构建vocal list的啊？没这个怎么做映射Token化啊？没想通

### 阅读
1. 整体的生成过程如下, 通过将item的各种基础属性信息收集起来，使用文本向量化的模型（论文中用的是Sentence-T5, 768维）将这些信息构建为基础emb，之后通过RQ-VAE来生成每个item的语义ID(文中是个四元组，最后一个位置用于解决冲突)，
再使用Transformer进行next token的自回归预测生成  
![img.png](../pic/recall_0703_img1.png)     


进一步细化整体结构，a图表示整个量化生成语义ID的过程，b图表示使用Transformer进行序列到序列的生成模型构建
![img.png](../pic/recall_0703_img2.png)

2. RQ-VAE的生成过程
![img.png](../pic/recall_0703_img3.png)
